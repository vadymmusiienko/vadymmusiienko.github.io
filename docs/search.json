[
  {
    "objectID": "mini.html",
    "href": "mini.html",
    "title": "Mini-projects",
    "section": "",
    "text": "1. Ukrainian Refugees\n\nAnalysis of Refugees Data\nPlot top 5 countries with most Ukrainian refugees.\n\nlibrary(tidyverse)\n\n# Load the data\ntuesdata &lt;- tidytuesdayR::tt_load('2023-08-22')\n\n# Get a dataframe\npopulation &lt;- tuesdata$population\n\n# Wrangle and visualize\npopulation |&gt;\n  filter(coo == \"UKR\", year &gt;= 2022) |&gt;\n  group_by(coa_name) |&gt;\n  summarize(total_refugees = sum(refugees, na.rm = TRUE)) |&gt;\n  arrange(desc(total_refugees)) |&gt;\n  slice_head(n = 5) |&gt;\n  mutate(country = recode(coa_name, \"Czechia\" = \"Czech Republic\",\n                           \"Russian Federation\" = \"Russia\",\n                           \"United Kingdom of Great Britain and Northern Ireland\"\n                           = \"UK\")) |&gt;\n  ggplot(aes(fct_reorder(country, total_refugees), total_refugees, fill = country)) +\n  geom_col(width = 0.7) +\n  scale_y_continuous(labels = scales::comma_format()) +\n   labs(\n    title = \"Top 5 Countries with Most Ukrainian Refugees\",\n    x = NULL,\n    y = \"Total Refugees\",\n  ) +\n  theme_minimal() +\n  theme(legend.position = \"none\",\n        plot.title = element_text(hjust = 0.5))\n\n\n\n\n\n\n\n\nThis bar chart displays the top 5 countries hosting the most Ukrainian refugees (since the beginning of the full-scale invasion).The y-axis represents the total number of refugees, with Russia hosting the highest number, exceeding a million. Germany and Poland follow closely with almost a million refugees each, while the Czech Republic has just under 500,000. The UK has the fewest refugees among the five countries, with less than 250,000.\nKey observations:\nThe significant difference in the number of Ukrainian refugees in Russia compared to other countries is striking, prompting the question: why are people fleeing the war to the very aggressor? This is primarily because Russian forces in occupied Ukrainian territories forcibly deporting people to Russia, labeling them as “refugees” and leaving them with no other option. In contrast, Poland and Germany are popular destinations for Ukrainian refugees, likely due to their proximity and strong support.\n\n\n\n2. Gender Trends at the International Mathematical Olympiad\n\nAnalysis of International Mathematical Olympiad (IMO) Data\nPlot total male and female contestants\n\nlibrary(tidyverse)\n\n# Load the data\ntuesdata &lt;- tidytuesdayR::tt_load('2024-09-24')\n\n# Get a dataframe\ntimeline_df &lt;- tuesdata$timeline_df\n\n# Wrangle and visualize\ntimeline_df |&gt; \n  group_by(year) |&gt;\n  summarize(Female = sum(female_contestant, na.rm = TRUE),\n            Male = sum(male_contestant, na.rm = TRUE)) |&gt;\n  pivot_longer(cols = c(Female, Male), \n               names_to = \"gender\", \n               values_to = \"total\") |&gt;\n  ggplot(aes(x = year, y = total, color = gender)) +\n  geom_line(linewidth = 1.2) +\n  labs(title = \"Total Male and Female IMO Contestants Over Time\",\n       x = NULL,\n       y = \"Total Contestants\",\n       color = \"Gender\") +\n  theme_minimal() +\n  theme(plot.title = element_text(hjust = 0.5))\n\n\n\n\n\n\n\n\nThis plot shows the total number of male and female contestants in the International Mathematical Olympiad (IMO) over time, from the 1950s to the 2020s. The blue line represents the number of male participants, and the red line represents the number of female participants.\nKey observations:\nThe number of male contestants has increased dramatically over time, particularly from the 1980s onward, reaching over 400 participants in recent years. The number of female contestants, while also increasing slightly over time, remains significantly lower compared to male contestants.There is a noticeable gender disparity, with male contestants consistently outnumbering female contestants throughout the entire period. The plot highlights a persistent gender gap in participation, despite the overall growth in the number of contestants."
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "About this site"
  },
  {
    "objectID": "sleep.html",
    "href": "sleep.html",
    "title": "Impact of Exercise on Sleep Quality",
    "section": "",
    "text": "Introduction\nPhysical activity is widely believed to positively affect various aspects of health, including sleep quality. Sleep efficiency, a measure of the proportion of time spent asleep while in bed, is an important indicator of sleep quality. Despite common beliefs, the relationship between exercise and sleep efficiency needs to be thoroughly studied. This analysis explores the impact of physical activity on sleep efficiency using data from PhysioNet. By categorizing participants into active and inactive groups based on their total exercise duration and intensity, we aim to determine whether higher physical activity levels are associated with improved sleep efficiency.\n\nResearch Hypothesis\nHigher levels of physical activity positively affect sleep efficiency.\n\n\nNull Hypothesis (H₀)\nThere is no significant difference in sleep efficiency between individuals with higher levels of physical activity and those with lower levels of physical activity.\n\n\nAlternative Hypothesis (H₁)\nIndividuals with higher levels of physical activity have significantly greater sleep efficiency compared to those with lower levels of physical activity.\n\n\n\nData\nTo answer the question of whether physical activity positively affects sleep efficiency, we chose a dataset from Multilevel Monitoring of Activity and Sleep in Healthy People by PhysioNet (MMASH). The data were collected and provided by BioBeats in collaboration with researchers from the University of Pisa. The dataset contains information about 22 healthy young adult males. The subjects were observed for 24 hours, during which they slept twice. Consequently, the dataset consists of variables for both day 1 and day 2.\nThe data consists of directories for each of the 22 participants, with 7 files in each participant’s folder.\nAlthough MMASH provides seven files per participant, this analysis focuses on two key files: Sleep.csv and Activity.csv.\nSleep.csv contains information about sleep duration and sleep quality of the participants, while Activity.csv provides a list of activity categories throughout the day. For this analysis, we focus specifically on physical activities:\nLight movement (4): Slow to medium-paced activities like walking, household chores, and work-related movements. Medium movement (5): More vigorous activities such as fast walking and biking. Heavy movement (6): High-intensity exercises like gym workouts and running. As for the sleep data, we will focus on the Latency Efficiency variable, which is measured as a percentage of sleep time relative to total time spent in bed.\n\n\nAnalysis\n\nLoad Necessary Libraries\nLoad R libraries for data manipulation, analysis, and visualization.\n\nlibrary(tidyverse)\nlibrary(lubridate)\n\n\n\nLoad and wrangle the data\nSince the data is organized into separate directories and files for each participant in the study, we need to read all the relevant files for each participant and extract only the columns of interest.\nThe data includes the start and end times of each activity as well as the start and end times of sleep. As a result, we will need to calculate the duration of each activity and sleep ourselves.\n\n# Path to the main data folder (with 22 directories)\ndata_path &lt;- \"data/SleepUsers/\"\n\n# Get the list of user folders\nuser_folders &lt;- list.dirs(path = data_path, full.names = TRUE, recursive = FALSE)\n\n# Function to read Activity.csv file for a user (returns a dataframe)\nread_activity_data &lt;- function(user_folder) {\n  # Access the activity file\n  activity_file &lt;- file.path(user_folder, \"Activity.csv\")\n  \n  # Read the activity file into a dataframe and add a column with user number\n  activity_df &lt;- read.csv(activity_file) |&gt;\n    mutate(user = basename(user_folder))\n  \n  return(activity_df)\n}\n\n# Function to read Sleep.csv file for a user (returns a dataframe)\nread_sleep_data &lt;- function(user_folder) {\n  # Access the sleep file\n  sleep_file &lt;- file.path(user_folder, \"Sleep.csv\")\n\n  # Read the sleep file into the dataframe and add a column with user number\n  sleep_df &lt;- read.csv(sleep_file) |&gt;\n    # Select only Sleep Efficiency column\n    select(Efficiency) |&gt;\n    mutate(user = basename(user_folder))\n  \n  return(sleep_df)\n}\n\n# Read and combine Activity.csv files\nactivity_df &lt;- user_folders |&gt;\n  map(read_activity_data) |&gt; list_rbind()\n\n# Read and combine Sleep.csv files\nsleep_df &lt;- user_folders |&gt;\n  map(read_sleep_data) |&gt; \n  list_rbind() |&gt;\n  rename(\n    efficiency = Efficiency\n  )\n\n# Calculate average sleep efficiency over the 2 days of the experiment for each user\nsleep_df &lt;- sleep_df |&gt; \n  group_by(user) |&gt;\n  summarize(avr_sleep_efc = mean(efficiency))\n\n# Select only rows with physical activity (light, medium, heavy)\nactivity_df &lt;- activity_df |&gt;\n  rename(\n    activity = Activity\n  ) |&gt;\n  filter(activity %in% c(4, 5, 6)) |&gt;\n  mutate(activity = case_when(\n    activity == 4 ~ \"light\",\n    activity == 5 ~ \"medium\",\n    activity == 6 ~ \"heavy\",\n  ), \n  # Convert start and end times to time objects (lubridate)\n  Start = hm(Start),\n  End = hm(End))\n\n# Add a duration of the activity column (in minutes) and delete End and Start columns\nactivity_df &lt;- activity_df |&gt;\n  mutate(duration = as.numeric(End - Start) / 60) |&gt;\n  select(-c(\"End\", \"Start\"))\n\n# Calculate total physical activity duration per user over 2 days and pivot wider\nactivity_df &lt;- activity_df |&gt;\n  group_by(user, activity) |&gt;\n  summarise(total_duration = sum(duration, na.rm = TRUE)) |&gt;\n  ungroup() |&gt;\n  pivot_wider(names_from = activity, values_from = total_duration, \n              values_fill = 0)\n\n# View first 5 rows\nhead(activity_df, n = 5)\n\n# A tibble: 5 × 4\n  user    heavy light medium\n  &lt;chr&gt;   &lt;dbl&gt; &lt;dbl&gt;  &lt;dbl&gt;\n1 user_1    130    10     10\n2 user_10    90    40      0\n3 user_11    77     0      0\n4 user_12    95     0     40\n5 user_13   150     0      0\n\nhead(sleep_df, n = 5)\n\n# A tibble: 5 × 2\n  user    avr_sleep_efc\n  &lt;chr&gt;           &lt;dbl&gt;\n1 user_1           89.6\n2 user_10          75.1\n3 user_12          94.2\n4 user_13          76.5\n5 user_14          90.8\n\n\nNow that we have two dataframes with sleep and activity information, we can merge them together by users.\n\n# Merge activity and sleep dataframes based on user\nmerged_data &lt;- activity_df |&gt; inner_join(sleep_df, by = c(\"user\"))\n\n# View the first 5 rows\nhead(merged_data, n = 5)\n\n# A tibble: 5 × 5\n  user    heavy light medium avr_sleep_efc\n  &lt;chr&gt;   &lt;dbl&gt; &lt;dbl&gt;  &lt;dbl&gt;         &lt;dbl&gt;\n1 user_1    130    10     10          89.6\n2 user_10    90    40      0          75.1\n3 user_12    95     0     40          94.2\n4 user_13   150     0      0          76.5\n5 user_14    58     0      0          90.8\n\n\nNow that we have our merged data, you may notice that most activity durations are whole numbers. Although the original source does not explain why these convenient numbers occur, we assume it is due to rounding. It is likely that participants provided approximate times that were rounded to whole numbers. (However, there are a few durations that are neither divisible by 5 nor 10.)\n\n\nVisualize the relationship of interest\nSince there are three different activities, we want to combine them into one. However, heavy should weigh more than medium, and medium more than light. Thus, let’s introduce multipliers: heavy will be 3 as it is the most intensive activity, medium will be 2, and light will be 1.\n\n# Multipliers for each activity\nheavy_multiplier &lt;- 3\nmedium_multiplier &lt;- 2\nlight_multiplier &lt;- 1\n\n# Create a dataframe with total activity (light, medium, and heavy) for each user\nactivity &lt;- merged_data |&gt; group_by(user) |&gt; \n  summarize(\n    total_exercise = heavy * heavy_multiplier + medium * medium_multiplier + light * light_multiplier, \n    avr_sleep_efc = avr_sleep_efc\n  ) |&gt; \n  ungroup()\n\n# View first 5 rows\nhead(activity, n = 5)\n\n# A tibble: 5 × 3\n  user    total_exercise avr_sleep_efc\n  &lt;chr&gt;            &lt;dbl&gt;         &lt;dbl&gt;\n1 user_1             420          89.6\n2 user_10            310          75.1\n3 user_12            365          94.2\n4 user_13            450          76.5\n5 user_14            174          90.8\n\n\nTo determine who counts as an active person, let’s find the average minutes of activity among the participants and divide the population into two parts: active and non-active, based on the average.\n\n# Average time active in the population\nactive_avr &lt;- activity |&gt; summarize(avr_time_active = mean(total_exercise)) |&gt;\n  as.numeric()\n\n# See the average time active for a person in the population\nactive_avr\n\n[1] 331.0952\n\n\nThe average active time is 331 minutes, so let’s use it to determine whether a person is considered active or not. (If a person exercises more than the average, they are classified as active; otherwise, they are not.)\n\n# Add a logical column that represents whether a user was active or not\nactivity &lt;- activity |&gt;\n  mutate(active = ifelse(total_exercise &gt; active_avr, \"Yes\", \"No\")) \n\n# View first 5 rows\nhead(activity, n = 5)\n\n# A tibble: 5 × 4\n  user    total_exercise avr_sleep_efc active\n  &lt;chr&gt;            &lt;dbl&gt;         &lt;dbl&gt; &lt;chr&gt; \n1 user_1             420          89.6 Yes   \n2 user_10            310          75.1 No    \n3 user_12            365          94.2 Yes   \n4 user_13            450          76.5 Yes   \n5 user_14            174          90.8 No    \n\n\nThe data looks good, so let’s go ahead and create a plot to see if there are any differences between groups.\n\nactivity |&gt; \n  ggplot(aes(x = active, y = avr_sleep_efc)) +\n  geom_boxplot() +\n  labs(\n    x = \"Active\",\n    y = \"Sleep Efficiency\",\n    title = \"Effect of Physical Activity on Sleep Quality\"\n  ) +\n  theme_minimal()\n\n\n\n\n\n\n\n\nFrom this boxplot, we can see that, in our population, people who exercise more tend to have slightly better sleep efficiency (percentage of sleep time relative to total time spent in bed).\n\n\nCalculate the observed statistics\n\n# Calculate the mean and median of active and non-active groups\nactivity |&gt; group_by(active) |&gt; \n  summarize(avr_quality = mean(avr_sleep_efc),\n            med_quality = median(avr_sleep_efc)\n)\n\n# A tibble: 2 × 3\n  active avr_quality med_quality\n  &lt;chr&gt;        &lt;dbl&gt;       &lt;dbl&gt;\n1 No            82.2        84.3\n2 Yes           85.6        86.9\n\n\nThe statistics above confirm that, on average, people in our population who were active had slightly better sleep efficiency (percentage of sleep time relative to total time spent in bed) than those who didn’t exercise as much.\n\n# Difference in means and medians\nactivity |&gt; group_by(active) |&gt; \n  summarize(avr_quality = mean(avr_sleep_efc),\n            med_quality = median(avr_sleep_efc) \n) |&gt;\n  summarize(\n    ave_diff = diff(avr_quality),\n    med_diff = diff(med_quality)\n  )\n\n# A tibble: 1 × 2\n  ave_diff med_diff\n     &lt;dbl&gt;    &lt;dbl&gt;\n1     3.41     2.60\n\n\nThe difference in mean sleep efficiency between people who exercise more than average and those who do not is 3.4%, and the difference in medians is 2.6%.\n\n\nGenerate a null sampling distribution.\n\n# Function to generate a null sampling distribution\nperm_data &lt;- function(rep, data) {\n  data |&gt;\n    mutate(efc_perm = sample(avr_sleep_efc, replace = FALSE)) |&gt;\n    group_by(active) |&gt;\n    summarize(\n      obs_avr = mean(avr_sleep_efc),\n      obs_med = median(avr_sleep_efc),\n      perm_avr = mean(efc_perm),\n      perm_med = median(efc_perm)\n    ) |&gt;\n    summarize(\n      obs_avr_diff = diff(obs_avr),\n      obs_med_diff = diff(obs_med),\n      perm_avr_diff = diff(perm_avr),\n      perm_med_diff = diff(perm_med),\n      rep = rep\n    )\n}\n\n# Test the function\nmap(1:5, perm_data, data = activity) |&gt;\n  list_rbind()\n\n# A tibble: 5 × 5\n  obs_avr_diff obs_med_diff perm_avr_diff perm_med_diff   rep\n         &lt;dbl&gt;        &lt;dbl&gt;         &lt;dbl&gt;         &lt;dbl&gt; &lt;int&gt;\n1         3.41         2.60          1.77        -0.695     1\n2         3.41         2.60          7.28         9.39      2\n3         3.41         2.60          5.36         6.93      3\n4         3.41         2.60          4.78         8.07      4\n5         3.41         2.60          1.35         1.10      5\n\n\n\n\nVisualize the null sampling distribution (average)\n\nset.seed(47)\n\nperm_stats &lt;- map(1:500, perm_data, data = activity) |&gt; list_rbind()\n\nperm_stats |&gt; \n  ggplot(aes(perm_avr_diff)) + \n  geom_histogram() +\n  geom_vline(aes(xintercept = obs_avr_diff), color = \"red\") +\n  labs(\n    x = \"Permuted Average Difference\",\n    y = \"Frequency\",\n    title = \"Null Distribution of Average Differences\"\n  ) +\n  theme_minimal()\n\n\n\n\n\n\n\n\nThis histogram shows that the observed average difference is not significant and is likely to occur by chance.\n\n\nVisualize the null sampling distribution (median)\n\nperm_stats |&gt; \n  ggplot(aes(x = perm_med_diff)) + \n  geom_histogram() + \n  geom_vline(aes(xintercept = obs_med_diff), color = \"red\") +\n  labs(\n    x = \"Permuted Median Difference\",\n    y = \"Frequency\",\n    title = \"Null Distribution of Median Differences\"\n  ) +\n  theme_minimal()\n\n\n\n\n\n\n\n\nThis histogram shows that the observed median difference is not significant and is likely to occur by chance.\n\n\nP-value\n\nperm_stats |&gt; \n  summarize(p_val_avr = mean(perm_avr_diff &gt; obs_avr_diff),\n            p_val_med = mean(perm_med_diff &gt; obs_med_diff))\n\n# A tibble: 1 × 2\n  p_val_avr p_val_med\n      &lt;dbl&gt;     &lt;dbl&gt;\n1     0.124      0.21\n\n\n\n\n\nConclusion\nIn this study, we examined the impact of physical activity on sleep efficiency among 22 healthy young adult males. We categorized participants into active and inactive groups based on their total exercise duration, weighted by activity intensity. Our analysis showed that the active group had a slightly higher average sleep efficiency compared to the inactive group, with a mean difference of 3.4% and a median difference of 2.6%. This means that people who exercised more than the average slept 0.8% better.\nFrom these data, the observed differences seem to be consistent with the distribution of differences in the null sampling distribution. There is no evidence to reject the null hypothesis.\nWe cannot claim that, in the population, the average sleep efficiency for people who exercise more than the average person is larger than the average sleep efficiency for people who do not exercise more than the average person (p-value = 0.124).\nWe cannot claim that, in the population, the median sleep efficiency for people who exercise more than the average person is larger than the median sleep efficiency for people who do not exercise more than the average person (p-value = 0.21).\nTherefore, we conclude that there is not enough evidence to rule out chance. It’s important to note that the small sample size and the homogeneous nature of the participants (all healthy young adult males) may limit the generalizability of these findings. Further research with a larger and more diverse sample may be necessary to fully understand the relationship between physical activity and sleep efficiency.\n\n\nReference\nRossi, A., Da Pozzo, E., Menicagli, D., Tremolanti, C., Priami, C., Sirbu, A., Clifton, D., Martini, C., & Morelli, D. (2020). Multilevel Monitoring of Activity and Sleep in Healthy People (version 1.0.0). PhysioNet. https://doi.org/10.13026/cerq-fc86."
  },
  {
    "objectID": "presentation.html#data-frame-information",
    "href": "presentation.html#data-frame-information",
    "title": "Wine Reviews",
    "section": "Data frame information",
    "text": "Data frame information\nColumns\n\n\n[1] \"...1\"        \"country\"     \"description\" \"designation\" \"points\"     \n[6] \"price\"       \"province\"    \"variety\"    \n\n\nRows\n\n\nRows: 137,230\nColumns: 8\n$ ...1        &lt;dbl&gt; 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, …\n$ country     &lt;fct&gt; US, Spain, US, US, France, Spain, Spain, Spain, US, US, It…\n$ description &lt;chr&gt; \"This tremendous 100% varietal wine hails from Oakville an…\n$ designation &lt;chr&gt; \"Martha's Vineyard\", \"Carodorum Selección Especial Reserva…\n$ points      &lt;dbl&gt; 96, 96, 96, 96, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95…\n$ price       &lt;dbl&gt; 235, 110, 90, 65, 66, 73, 65, 110, 65, 60, 80, 48, 48, 90,…\n$ province    &lt;chr&gt; \"California\", \"Northern Spain\", \"California\", \"Oregon\", \"P…\n$ variety     &lt;chr&gt; \"Cabernet Sauvignon\", \"Tinta de Toro\", \"Sauvignon Blanc\", …"
  },
  {
    "objectID": "presentation.html#average-price-of-wine-by-country",
    "href": "presentation.html#average-price-of-wine-by-country",
    "title": "Wine Reviews",
    "section": "Average price of wine by country",
    "text": "Average price of wine by country\n\n\n The countries that produce the most expensive wines are the US, France, England, Hungary, and Luxembourg, with average prices ranging from 40 to 50 USD. On the other hand, the cheapest wine producers are Montenegro, Lithuania, Bulgaria, Bosnia, and Ukraine, where wines typically cost between 10 and 15 USD."
  },
  {
    "objectID": "presentation.html#code",
    "href": "presentation.html#code",
    "title": "Wine Reviews",
    "section": "Code",
    "text": "Code\n\nwine_data |&gt; \n  group_by(country) |&gt;\n  summarize(avr_price = mean(price)) |&gt;\n  ggplot(aes(fct_reorder(country, avr_price, .desc = TRUE), avr_price,\n             fill = country)) +\n  geom_col(color = \"black\", width = 0.8, show.legend = FALSE) +\n  labs(\n    title = \"Average price of wine by country\",\n    x = NULL,\n    y = \"Price in USD\"\n  ) +\n  theme_minimal() +\n  theme(axis.text.x = element_text(angle = 90, hjust = 1))"
  },
  {
    "objectID": "presentation.html#correlation-between-price-and-quality",
    "href": "presentation.html#correlation-between-price-and-quality",
    "title": "Wine Reviews",
    "section": "Correlation between Price and Quality",
    "text": "Correlation between Price and Quality\n\n\n There is definitely a correlation between price and rating, with more expensive wines tending to have higher ratings. However, the relationship is stronger in the 0 to 100 USD range, where price significantly impacts quality. Beyond 100 USD, wines are fairly similar in quality, with higher prices offering only a slight improvement."
  },
  {
    "objectID": "presentation.html#code-1",
    "href": "presentation.html#code-1",
    "title": "Wine Reviews",
    "section": "Code",
    "text": "Code\n\nwine_data |&gt;\n  filter(price &lt; 500) |&gt;\n  group_by(price) |&gt;\n  summarize(avr_rating = mean(points)) |&gt;\n  ggplot(aes(price, avr_rating)) +\n  geom_point(alpha = 0.5) +\n  geom_smooth(color = \"red\") +\n  labs(\n    title = \"Price vs. Quality\",\n    x = \"Price (USD)\",\n    y = \"Average rating (Points)\"\n  ) +\n  theme_minimal()"
  },
  {
    "objectID": "presentation.html#frequency-of-wine-adjectives",
    "href": "presentation.html#frequency-of-wine-adjectives",
    "title": "Wine Reviews",
    "section": "Frequency of wine adjectives",
    "text": "Frequency of wine adjectives"
  },
  {
    "objectID": "presentation.html#code-2",
    "href": "presentation.html#code-2",
    "title": "Wine Reviews",
    "section": "Code",
    "text": "Code\n\n# Create a vector with the adjectives\nadjectives &lt;- c(\"Acidic\", \"Astringent\", \"Barnyard\", \"Buttery\", \"Chewy\",\n                \"Earthy\", \"Flabby\", \"Fruity\", \"Fruit-forward\",\n                \"Herbaceous\", \"Jammy\", \"Juicy\", \"Musty\", \"Nutty\",\n                \"Oaky\", \"Opulent\", \"Perfumed\", \"Racy\", \"Spicy\",\n                \"Supple\", \"Tannic\", \"Toasty\", \"Vegetal\", \"Velvety\")\n\n# Create a regex pattern to search for adjectives\npattern &lt;- paste0(\"(?i)\", paste(adjectives, collapse = \"|\"))\n\n# Create a data frame with wine reviews where those adjectives were used\nwine_with_adj &lt;- wine_data |&gt; \n  mutate(\n    adjective = factor(tolower(str_extract(description, pattern)))\n    ) |&gt;\n  filter(!is.na(adjective))\n\n# Plot the frequency of each adjective\nwine_with_adj |&gt; group_by(adjective) |&gt;\n  summarise(count = n()) |&gt;\n  ggplot(aes(count, fct_reorder(adjective, count, .desc = TRUE), \n             fill = adjective)) +\n  geom_col(color = \"black\", width = 0.8, show.legend = FALSE) +\n  labs(\n    title = \"Adjective Frequency in Wine Reviews\",\n    y = NULL,\n    x = \"Number of times mentioned\"\n  ) +\n  theme_minimal()"
  },
  {
    "objectID": "presentation.html#average-price-and-rating-of-wine-by-flavor-note",
    "href": "presentation.html#average-price-and-rating-of-wine-by-flavor-note",
    "title": "Wine Reviews",
    "section": "Average Price and Rating of Wine by Flavor Note",
    "text": "Average Price and Rating of Wine by Flavor Note"
  },
  {
    "objectID": "presentation.html#code-3",
    "href": "presentation.html#code-3",
    "title": "Wine Reviews",
    "section": "Code",
    "text": "Code\n\nwine_with_adj |&gt; group_by(adjective) |&gt;\n  summarise(avr_price = mean(price), avr_points = mean(points)) |&gt;\n  ggplot(aes(avr_price, avr_points)) +\n  geom_point(size = 3) +\n  geom_label_repel(aes(label = adjective),\n                   size = 2.5, color = \"black\", fill = \"lightyellow\", \n                   label.size = 0.25, label.padding = 0.25, \n                   box.padding = 0.25) +\n  labs(\n    title = \"Average Price and Rating of Wine by Flavor Note\",\n    x = \"Average Price (USD)\",\n    y = \"Average Points (Points)\"\n  ) +\n  theme_minimal()\n\n\n\n\n\nWine Reviews: Analyzing Trends in Taste, Price, and Quality"
  },
  {
    "objectID": "wine.html",
    "href": "wine.html",
    "title": "Decoding Wine",
    "section": "",
    "text": "Introduction\nThe world of wine is rich with complexity, offering a diverse range of flavors, prices, and qualities. In this project we will analyze trends in wine characteristics by examining a Kaggle dataset of over 150,000 wine reviews. Through this exploration, we aim to uncover insights about the relationship between price, quality, and the descriptive notes used by wine experts. By analyzing factors such as the average price of wine by country, the correlation between price and ratings, and the impact of specific flavor notes on wine quality, this project seeks to provide a comprehensive view of what influences wine preferences and how they correlate to market values.\n\n\nAnalisys\n\nImport Libraries and Data\nThe tidyverse package is used for data visualization, while ggrepel adds functionality for labeling text on plots.\n\nlibrary(tidyverse)\nlibrary(ggrepel)\n\n# Load the data\nwine_data &lt;- read_csv(\"data/winemag-data_first150k.csv\")\n\n\n\nInspect the Dataset\nLet’s take a look at the first 10 records.\n\nhead(wine_data, n = 10)\n\n# A tibble: 10 × 11\n    ...1 country description designation points price province region_1 region_2\n   &lt;dbl&gt; &lt;chr&gt;   &lt;chr&gt;       &lt;chr&gt;        &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt;    &lt;chr&gt;    &lt;chr&gt;   \n 1     0 US      This treme… Martha's V…     96   235 Califor… Napa Va… Napa    \n 2     1 Spain   Ripe aroma… Carodorum …     96   110 Norther… Toro     &lt;NA&gt;    \n 3     2 US      Mac Watson… Special Se…     96    90 Califor… Knights… Sonoma  \n 4     3 US      This spent… Reserve         96    65 Oregon   Willame… Willame…\n 5     4 France  This is th… La Brûlade      95    66 Provence Bandol   &lt;NA&gt;    \n 6     5 Spain   Deep, dens… Numanthia       95    73 Norther… Toro     &lt;NA&gt;    \n 7     6 Spain   Slightly g… San Román       95    65 Norther… Toro     &lt;NA&gt;    \n 8     7 Spain   Lush cedar… Carodorum …     95   110 Norther… Toro     &lt;NA&gt;    \n 9     8 US      This re-na… Silice          95    65 Oregon   Chehale… Willame…\n10     9 US      The produc… Gap's Crow…     95    60 Califor… Sonoma … Sonoma  \n# ℹ 2 more variables: variety &lt;chr&gt;, winery &lt;chr&gt;\n\n\n\n\nClean the Data\nFrom inspecting the dataset, it appears that the country variable is of type , but we want it to be  (a factor) so that it can be ordered. Additionally, we will be analyzing the price and rating (points) of the wine, so we want to remove any rows where these variables contain missing (NA) values. Finally, this analysis will not include regions and wineries, so we will exclude those columns.\n\n# Clean up the data\nwine_data &lt;- wine_data |&gt; filter(!(is.na(price) | is.na(country))) |&gt;\n  mutate(country = as.factor(country)) |&gt;\n  select(-c(region_1, region_2, winery))\n\n\n\nAverage price by country\nOne of the first interesting insights would be to determine which countries produce the most expensive and the cheapest wines. To find this out, let’s create a plot showing the average wine prices for each country in the dataset.\n\nwine_data |&gt; \n  group_by(country) |&gt;\n  summarize(avr_price = mean(price)) |&gt;\n  ggplot(aes(fct_reorder(country, avr_price, .desc = TRUE), avr_price,\n             fill = country)) +\n  geom_col(color = \"black\", width = 0.8, show.legend = FALSE) +\n  labs(\n    title = \"Average price of wine\",\n    x = NULL,\n    y = \"Price in USD\"\n  ) +\n  theme_minimal() +\n  theme(axis.text.x = element_text(angle = 90, hjust = 1))\n\n\n\n\n\n\n\n\nThe countries that produce the most expensive wines are the US, France, England, Hungary, and Luxembourg, with average prices ranging from 40 to 50 USD. On the other hand, the cheapest wine producers are Montenegro, Lithuania, Bulgaria, Bosnia, and Ukraine, where wines typically cost between 10 and 15 USD.\n\n\nCorrelation between Price and Quality\nAnother interesting question to explore is the correlation between price and quality. Are more expensive wines actually better than cheaper ones? To find out, let’s visualize the relationship between prices and ratings (points).\n\nwine_data |&gt;\n  filter(price &lt; 500) |&gt;\n  group_by(price) |&gt;\n  summarize(avr_rating = mean(points)) |&gt;\n  ggplot(aes(price, avr_rating)) +\n  geom_point(alpha = 0.5) +\n  geom_smooth(color = \"red\") +\n  labs(\n    title = \"Price vs. Quality\",\n    x = \"Price (USD)\",\n    y = \"Average rating (Points)\"\n  ) +\n  theme_minimal()\n\n\n\n\n\n\n\n\nThere is definitely a correlation between price and rating, with more expensive wines tending to have higher ratings. However, the relationship is stronger in the 0 to 100 USD range, where price significantly impacts quality. Beyond 100 USD, wines are fairly similar in quality, with higher prices offering only a slight improvement.\n\n\nFlavor notes affect on price and quality\nWine can have a wide variety of flavors, described using different flavor notes. To determine which flavor notes are the most desirable, we identified 24 of the most commonly used adjectives to describe wine flavors. You can find the article with this information here.\nFirst, let’s see if these adjectives are actually used in the wine reviews and which ones are more common than others. We’ll plot the frequency of each adjective mentioned in the description section of the reviews.\n\n# Create a vector with the adjectives\nadjectives &lt;- c(\"Acidic\", \"Astringent\", \"Barnyard\", \"Buttery\", \"Chewy\",\n                \"Earthy\", \"Flabby\", \"Fruity\", \"Fruit-forward\",\n                \"Herbaceous\", \"Jammy\", \"Juicy\", \"Musty\", \"Nutty\",\n                \"Oaky\", \"Opulent\", \"Perfumed\", \"Racy\", \"Spicy\",\n                \"Supple\", \"Tannic\", \"Toasty\", \"Vegetal\", \"Velvety\")\n\n# Create a regex pattern to search for adjectives\npattern &lt;- paste0(\"(?i)\", paste(adjectives, collapse = \"|\"))\n\n# Create a data frame with wine reviews where those adjectives were used\nwine_with_adj &lt;- wine_data |&gt; \n  mutate(\n    adjective = factor(tolower(str_extract(description, pattern)))\n    ) |&gt;\n  filter(!is.na(adjective))\n\n# Plot the frequency of each adjective\nwine_with_adj |&gt; group_by(adjective) |&gt;\n  summarise(count = n()) |&gt;\n  ggplot(aes(count, fct_reorder(adjective, count, .desc = TRUE), \n             fill = adjective)) +\n  geom_col(color = \"black\", width = 0.8, show.legend = FALSE) +\n  labs(\n    title = \"Adjective Frequency in Wine Reviews\",\n    y = NULL,\n    x = \"Number of times mentioned\"\n  ) +\n  theme_minimal()\n\n\n\n\n\n\n\n\nWe can see that most of these adjectives are widely used among wine experts. “Fruity,” “Spicy,” “Tannic,” and “Juicy” appear in over 5,000 reviews, making them very common. On the other hand, adjectives like “Musty,” “Flabby,” and “Fruit-forward” are relatively rare.\nNow that we know wine experts frequently use these words, let’s explore which flavor notes are associated with more sophisticated wines. To visualize this, we’ll plot the average price and rating for each adjective.\n\n# Plot average price and rating depending on a flavor note\nwine_with_adj |&gt; group_by(adjective) |&gt;\n  summarise(avr_price = mean(price), avr_points = mean(points)) |&gt;\n  ggplot(aes(avr_price, avr_points)) +\n  geom_point(size = 3) +\n  geom_label_repel(aes(label = adjective),\n                   size = 2.5, color = \"black\", fill = \"lightyellow\", \n                   label.size = 0.25, label.padding = 0.25, \n                   box.padding = 0.25) +\n  labs(\n    title = \"Average Price and Rating of Wine by Flavor Note\",\n    x = \"Average Price (USD)\",\n    y = \"Average Points (Points)\"\n  ) +\n  theme_minimal()\n\n\n\n\n\n\n\n\nThe clear winner among the flavor notes is “opulent,” which is often associated with the most sophisticated wines. Opulent wines not only have the highest prices but also receive the best ratings. Close contenders are “velvety” and “astringent.” Both velvety and astringent wines are also quite expensive, with velvety wines having higher ratings. In contrast, the cheapest and lowest-quality wines are described as “musty,” “flabby,” and “vegetal.”\n\n\nBerry notes\nWhile reviewing the descriptions, we noticed that wine is often described as having various berry flavor notes. Let’s conduct a similar analysis to determine which berry flavor is considered the most “expensive.”\nThe regular expression I used for matching berries is: (?i)\\b\\w+erry\\b.\n\n# A data frame with wines that were described with some berry\nberries &lt;- wine_data |&gt;\n  filter(str_detect(description, \"(?i)\\\\b\\\\w+erry\\\\b\")) |&gt;\n  mutate(berry = tolower(str_extract(description, \"(?i)\\\\b\\\\w+erry\\\\b\")))\n\n# The 6 most used berries used to describe wine (except for just \"berry\")\ntopberries &lt;- berries |&gt; group_by(berry) |&gt;\n  summarize(count = n()) |&gt; \n  arrange(desc(count)) |&gt;\n  filter(berry != \"berry\") |&gt;\n  slice_head(n = 6)\n\n# Plot the price of wine with different berry notes\nberries |&gt; \n  filter(berry %in% topberries$berry) |&gt;\n  group_by(berry)|&gt;\n  summarize(avr_price = mean(price)) |&gt;\n  ggplot(aes(fct_reorder(berry, avr_price, .desc = TRUE), avr_price,\n             fill = berry)) +\n  geom_col(color = \"black\", show.legend = FALSE) +\n  coord_cartesian(ylim = c(25, 45)) +\n  labs(\n    title = \"Average Price of Wine with Different Berry Notes\",\n    y = \"Average price (USD)\",\n    x = NULL\n  ) +\n  geom_text(aes(label = berry), color = \"black\", \n            position = position_stack(vjust = 0.9),\n            size = 3.5,\n            alpha = 0.8) +\n  theme_minimal() +\n  theme(axis.text.x = element_blank())\n\n\n\n\n\n\n\n\nWines with blackberry flavor tend to be the most expensive, with an average price of around $42. In contrast, strawberry-flavored wines are the cheapest, averaging $32.\n\n\n\nConclusion\nThis project explored the relationships between wine characteristics, including price, quality, and flavor notes, based on a dataset of over 150,000 wine reviews. By examining the average price of wine by country, we uncovered interesting trends in global wine pricing. We also explored the correlation between price and quality, revealing that while more expensive wines tend to have higher ratings, the relationship is less pronounced at higher price points. Further, our analysis of flavor notes showed that descriptors like “opulent,” “velvety,” and “astringent” are linked to higher-priced and higher-rated wines, while terms like “musty” and “flabby” correlate with lower-quality wines. Additionally, berry flavor notes such as “blackberry” were associated with the most expensive wines. Overall, this exploration provides a comprehensive look at the factors that influence wine preferences and their market value, offering useful insights for both wine enthusiasts and producers."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Vadym Musiienko",
    "section": "",
    "text": "Welcome to my page!\nI’m Vadym — a Software Engineer and Pomona College student passionate about working with data and building fun projects."
  },
  {
    "objectID": "WAI.html",
    "href": "WAI.html",
    "title": "Wideband Acoustic Immittance",
    "section": "",
    "text": "This analysis explores the Wideband Acoustic Immittance (WAI) Database hosted by Smith College. The database contains measurements of acoustic properties in human ears, including absorbance, power reflectance, impedance, and other related quantities. Implemented in MySQL, this online database serves as a repository for normative adult WAI measures, facilitating data sharing and analysis across different research studies. The database is publicly accessible here.\nThe analysis has two primary objectives:\n\nReproduce Figure 1 from Voss (2020), which illustrates mean absorbances across various studies\nVisualize WAI mean absorbance across various studies for male and female participats\n\n\n\n\nlibrary(tidyverse)\nlibrary(dbplyr)\nlibrary(RMariaDB)\n\n\n\n\n\ncon_wai &lt;- dbConnect(\n  MariaDB(), host = \"scidb.smith.edu\",\n  user = \"waiuser\", password = \"smith_waiDB\", \n  dbname = \"wai\"\n)"
  },
  {
    "objectID": "WAI.html#data",
    "href": "WAI.html#data",
    "title": "Wideband Acoustic Immittance",
    "section": "Data",
    "text": "Data\nFirstly, we need to understand the structure of the SQL database, including its tables and the variables within them.\n\nData base structure\n\nSHOW TABLES;\n\n\n7 records\n\n\nTables_in_wai\n\n\n\n\nCodebook\n\n\nMeasurements\n\n\nMeasurements_pre2020\n\n\nPI_Info\n\n\nPI_Info_OLD\n\n\nSubjects\n\n\nSubjects_pre2020\n\n\n\n\n\nThe WAI database consists of 7 tables, but our analysis will focus on the three most relevant and up-to-date tables: Measurements, PI_Info, and Subjects.\n\n\nMeasurements table\n\nSELECT *\nFROM Measurements\nLIMIT 0, 5;\n\n\n5 records\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nIdentifier\nSubjectNumber\nSession\nEar\nInstrument\nAge\nAgeCategory\nEarStatus\nTPP\nAreaCanal\nPressureCanal\nSweepDirection\nFrequency\nAbsorbance\nZmag\nZang\n\n\n\n\nAbur_2014\n1\n1\nLeft\nHearID\n20\nAdult\nNormal\n-5\n4.42e-05\n0\nAmbient\n210.938\n0.0333379\n113780000\n-0.233504\n\n\nAbur_2014\n1\n1\nLeft\nHearID\n20\nAdult\nNormal\n-5\n4.42e-05\n0\nAmbient\n234.375\n0.0315705\n103585000\n-0.235778\n\n\nAbur_2014\n1\n1\nLeft\nHearID\n20\nAdult\nNormal\n-5\n4.42e-05\n0\nAmbient\n257.812\n0.0405751\n92951696\n-0.233482\n\n\nAbur_2014\n1\n1\nLeft\nHearID\n20\nAdult\nNormal\n-5\n4.42e-05\n0\nAmbient\n281.250\n0.0438399\n86058000\n-0.233421\n\n\nAbur_2014\n1\n1\nLeft\nHearID\n20\nAdult\nNormal\n-5\n4.42e-05\n0\nAmbient\n304.688\n0.0486400\n79492800\n-0.232931\n\n\n\n\n\nThe Measurements table contains the core data of our analysis, including publication identifiers, instrument information, and most importantly, frequency and absorbance measurements. This table links to PI_Info through the Identifier column and to Subjects through the SubjectNumber column.\n\n\nPI_Info table\n\nSELECT Identifier, Year, Authors, AuthorsShortList\nFROM PI_Info \nLIMIT 0, 5;\n\n\n5 records\n\n\n\n\n\n\n\n\nIdentifier\nYear\nAuthors\nAuthorsShortList\n\n\n\n\nAbur_2014\n2014\nDefne Abur, Nicholas J. Horton, and Susan E. Voss\nAbur et al.\n\n\nAithal_2013\n2013\nSreedevi Aithal, Joseph Kei, Carlie Driscoll, and Asaduzzaman Khan\nAithal et al.\n\n\nAithal_2014\n2014\nSreedevi Aithal, Joseph Kei, and Carlie Driscoll\nAithal et al.\n\n\nAithal_2014b\n2014\nSreedevi Aithal, Joseph Kei, and Carlie Driscoll\nAithal et al.\n\n\nAithal_2015\n2015\nSreedevi Aithal, Joseph Kei, Carlie Driscoll, Asaduzzaman Khan, and Andrew Swanston\nAithal et al.\n\n\n\n\n\nThe PI_Info table provides metadata about each publication, including author information and publication year.\n\n\nSubjects table\n\nSELECT *\nFROM Subjects\nLIMIT 0, 5;\n\n\n5 records\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nIdentifier\nSubjectNumber\nSessionTotal\nAgeFirstMeasurement\nAgeCategoryFirstMeasurement\nSex\nRace\nEthnicity\nLeftEarStatusFirstMeasurement\nRightEarStatusFirstMeasurement\nSubjectNotes\n\n\n\n\nAbur_2014\n1\n7\n20\nAdult\nFemale\nUnknown\nUnknown\nNormal\nNormal\n\n\n\nAbur_2014\n3\n8\n19\nAdult\nFemale\nUnknown\nUnknown\nNormal\nNormal\nSession 5 not included do to acoustic leak\n\n\nAbur_2014\n4\n7\n21\nAdult\nFemale\nUnknown\nUnknown\nNormal\nNormal\n\n\n\nAbur_2014\n6\n8\n21\nAdult\nFemale\nUnknown\nUnknown\nNormal\nNormal\n\n\n\nAbur_2014\n7\n5\n20\nAdult\nFemale\nUnknown\nUnknown\nNormal\nNormal\n\n\n\n\n\n\nThe Subjects table contains demographic information about study participants, including ethnicity, sex, and other relevant characteristics.\n\n\nPart 1: Reproducing Voss (2020) Figure 1\nTo recreate Figure 1 from Voss (2020), we first need to identify the publications included in the original figure. Let’s examine the available identifiers in the database.\n\nUnique identifiers\n\nSELECT DISTINCT(Identifier) FROM Measurements;\n\n\nDisplaying records 1 - 10\n\n\nIdentifier\n\n\n\n\nAbur_2014\n\n\nAithal_2013\n\n\nAithal_2014\n\n\nAithal_2014b\n\n\nAithal_2015\n\n\nAithal_2017a\n\n\nAithal_2017b\n\n\nAithal_2019a\n\n\nAithal_2019b\n\n\nAithal_2020a\n\n\n\n\n\nAfter reviewing the list of Identifiers, I identified the following publications used in Voss (2020): Abur_2014, Feeney_2017, Groon_2015, Lewis_2015, Liu_2008, Rosowski_2012, Shahnaz_2006, Shaver_2013, Sun_2016, Voss_1994, Voss_2010,and Werner_2010.\n\n\nData acquisition\nTo recreate the figure, we need to calculate average absorbance values across frequencies for each publication. The legend requires additional publication information retrieved from the PI_Info table.\nQuery:\n\nSELECT \n    Frequency,\n    AVG(Absorbance) AS Mean_absorbance,\n    CONCAT(pi.AuthorsShortList, ' (', pi.Year, ') N=', \n    COUNT(DISTINCT SubjectNumber, Ear), ': ', m.Instrument) AS Publication\nFROM Measurements AS m\nJOIN PI_Info AS pi ON m.Identifier = pi.Identifier\nWHERE m.Identifier IN \n  (\"Abur_2014\", \"Feeney_2017\", \"Groon_2015\", \"Lewis_2015\", \"Liu_2008\",\n  \"Rosowski_2012\", \"Shahnaz_2006\", \"Shaver_2013\", \"Sun_2016\",\n  \"Voss_1994\", \"Voss_2010\", \"Werner_2010\")\nGROUP BY Frequency, m.Identifier, pi.Year, m.Instrument\n\n\n\nCustom theme\nWe designed a custom theme for the plot to align with the style of the original figure.\n\ncustom_theme &lt;- theme(\n  # Background\n  panel.background = element_rect(fill = \"white\", color = \"grey\"),\n  panel.grid.minor = element_line(color = \"gray80\"), \n  \n  # Axis text and titles\n  axis.text = element_text(size = 8),\n  axis.title = element_text(size = 11, colour = \"black\"),\n  \n  # Legend\n  legend.position = c(0, 1),\n  legend.justification = c(0, 1),\n  legend.key.size = unit(0.4, \"cm\"),\n  legend.text = element_text(size = 9),\n  legend.key = element_rect(fill = \"white\", color = \"white\"),\n  legend.background = element_rect(\n    fill = \"white\",\n    color = \"grey\",\n    size = 0.5\n  ),\n  \n  # Title\n  plot.title = element_text(hjust = 0.5, size = 14, face = \"bold\"),\n  \n  # Ticks on x and y axis\n  axis.ticks = element_line(color = \"grey\", size = 0.5),\n  axis.ticks.length = unit(0.2, \"cm\")\n)\n\n\n\nRecreate Figure 1 from Voss (2020)\nHere is the code for the final visualization:\n\nfigure_data |&gt; \n  ggplot(\n  aes(Frequency, Mean_absorbance, color = Publication)\n  ) +\n  geom_line(size = 1) +\n  \n  # Zoom in on the interval of interest\n  coord_cartesian(xlim = c(200, 8000), ylim = c(0, 1)) +\n  \n  # Add custom ticks on x-axis\n  scale_x_continuous(\n    breaks = c(200, 400, 600, 800, 1000, 2000, 4000, 6000, 8000),\n    trans = \"pseudo_log\"\n                 ) +\n  \n  # Add custom ticks on y-axis\n  scale_y_continuous(\n    breaks = c(0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1),\n                 ) +\n  \n  # Add the labels\n  labs(\n    title = \"Mean absorbance from each population in WAI database\",\n    x = \"Frequency (Hz)\",\n    y = \"Mean absorbance\",\n    color = NULL\n  ) + \n  \n  # Apply the custom theme\n  custom_theme\n\n\n\n\n\n\n\n\nVoss (2020) describes the figure as follows:\n“Mean absorbances for the 12 studies within the WAI database as of July 1, 2019. The legend includes peer-reviewed publications, the number of individual ears, and the equipment used in the studies. For ears with multiple measurements, the average was used. The figure includes all ears in the database, without controlling for the number of ears from each subject.”\n\n\n\nPart 2: Mean absorbance for males and females\nThis analysis aims to determine whether there is a difference in mean absorbance between male and female participants. As in the previous analysis, we use the same set of publications.\n\nData acquisition\nParticipant sex information is retrieved from the Subjects table, which is joined with the Measurements table to link absorbance data with each subject’s personal information.\nQuery:\n\nSELECT \n    Frequency,\n    CASE \n      WHEN UPPER(Sex) LIKE '%MALE%' THEN 'Male'\n      WHEN UPPER(Sex) LIKE '%FEMA%' THEN 'Female'\n    END AS Sex,\n    AVG(Absorbance) AS Mean_absorbance,\n    CONCAT(Sex, ' N=', \n    COUNT(DISTINCT m.SubjectNumber, Ear), ': ', m.Identifier) AS Label\nFROM Measurements AS m\nJOIN Subjects AS s ON m.SubjectNumber = s.SubjectNumber\nWHERE m.Identifier IN (\"Abur_2014\", \"Feeney_2017\", \"Groon_2015\", \"Lewis_2015\", \"Liu_2008\", \"Rosowski_2012\", \"Shahnaz_2006\", \"Shaver_2013\", \"Sun_2016\", \"Voss_1994\", \"Voss_2010\", \"Werner_2010\") \nAND Sex != 'Unknown'\nGROUP BY Frequency, s.Sex, m.Identifier\n\n\n\nVisualization\nThe following R code generates the visualization to compare mean absorbance between male and female participants:\n\n# Graph the data\nwai_sex |&gt;\n  ggplot(\n  aes(Frequency, Mean_absorbance, group = Label, color = Sex)\n  ) +\n  geom_line(size = 1) +\n  \n  # Zoom in on the interval of interest\n  coord_cartesian(xlim = c(200, 8000), ylim = c(0, 1)) +\n  \n  # Add custom ticks on x-axis\n  scale_x_continuous(\n    breaks = c(200, 400, 600, 800, 1000, 2000, 4000, 6000, 8000),\n    trans = \"pseudo_log\"\n                 ) +\n  \n  # Add custom ticks on y-axis\n  scale_y_continuous(\n    breaks = c(0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1),\n                 ) +\n  \n  # Add the labels\n  labs(\n    title = \"Mean absorbance for male and female\",\n    x = \"Frequency (Hz)\",\n    y = \"Mean absorbance\",\n    color = NULL\n  ) + \n  \n  # Apply the custom theme\n  custom_theme\n\n\n\n\n\n\n\n\nThis plot shows that female participants experience higher absorbance than males in the 800 Hz frequency range. However, the difference decreases after approximately 5000 Hz, where absorbance levels for both sexes become nearly identical.\n\n\nDisconnect from the Database\n\n# Disconnect from the database\ndbDisconnect(con_wai, shutdown = TRUE)\n\n\n\n\nAcknowledgments\nThe normative WAI database and corresponding website are funded by the National Institutes of Health, NIDCD (R15 DC014129). The server is hosted at Smith College.\n\nCitation\nThe DOI of this project is: doi.org/10.35482/egr.001.2022\nContributors to this work include:\n\nDr. Susan E. Voss, Picker Engineering Program, Smith College\nDr. Nicholas J. Horton, Professor of Statistics and Data Science, Amherst College\nDr. Benjamin Baumer, Statistical and Data Sciences, Smith College\nSuzanne Palmer Computing and Technical Services (CATS), Smith College\nMelinda Pontes ’15 Picker Engineering Program, Smith College\nWendy Jiang ’16 Picker Engineering Program, Smith College\nTinli Yarrington ’18 Picker Engineering Program, Smith College\nMelody Owen ’17 Amherst College Andrew Kim ’18 Amherst College Yuhan\nWen ’20 Picker Engineering Program, Smith College Julia Clark ’21\nPicker Engineering Program, Smith College Keane Ng ’23 Amherst\nCollege Jiayi Sun ’25 Picker Engineering Program, Smith College\nCasey Crary ’26 Amherst College"
  }
]